{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=6 color='green'><center>**Dynamic Architecture**</center></font>\n",
    "### **<center>Part 1<br/>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to train the dynmaic network architecture to learn the modality specific weights. The network trained here consists of three inputs (face, voice, video) and one output label, where label = 1 if face,video and voice are of same person, else label is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data using tensorflow data generators for efficient memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that parses the tf record\n",
    "def parser(tfRecord):\n",
    "   keys_to_features = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"video_raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"audio_raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\":     tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "   \n",
    "   parsed = tf.io.parse_single_example(tfRecord, keys_to_features)\n",
    "   image = tf.io.parse_tensor(parsed['image_raw'], out_type=tf.float64)\n",
    "   audio = tf.io.parse_tensor(parsed['audio_raw'], out_type=tf.double)\n",
    "   video = tf.io.parse_tensor(parsed['video_raw'], out_type=tf.double)\n",
    "   audio = tf.expand_dims(audio,axis=2)\n",
    "   label = tf.cast(parsed['label'], tf.int32)\n",
    "   label = tf.one_hot(label,2)\n",
    "   return {'faceInput':image,'voiceInput':audio, 'videoInput':video}, label\n",
    " \n",
    "# function to load dataset from the tfrecords file\n",
    "def get_train_data(filenames):\n",
    "  dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=40)\n",
    "  dataset = dataset.map(parser, num_parallel_calls=12)\n",
    "  dataset = dataset.batch(batch_size=32)\n",
    "  dataset = dataset.prefetch(buffer_size=2)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this path to the path file of tensorflow records\n",
    "inputDataPath = '/kaggle/input/tf-records-for-data/train.tfrecords'\n",
    "trainDataset = get_train_data(inputDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /kaggle/input/tf-records-for-data/train.tfrecords : The system cannot find the path specified.\r\n; No such process [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13360\\1903789362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# show a sample images and mfccs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# plotting the image input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'faceInput'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajini bopparam\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajini bopparam\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajini bopparam\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3041\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3043\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3044\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3045\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajini bopparam\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7215\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /kaggle/input/tf-records-for-data/train.tfrecords : The system cannot find the path specified.\r\n; No such process [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "# show a sample images and mfccs\n",
    "X_data, labels = next(iter(trainDataset))\n",
    "\n",
    "# plotting the image input\n",
    "plt.imshow(X_data['faceInput'][0])\n",
    "plt.show()\n",
    "\n",
    "mfcc=X_data['voiceInput'][0]\n",
    "print(f\"Shape of the mfcc co-efficients: {mfcc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D CNN Layer for processing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3D(keras.layers.Layer):\n",
    "  # name - name given to the sequential model, used to load pre-trained weights\n",
    "  def __init__(self, filters, kernel_size, padding,name=None):\n",
    "    \"\"\"\n",
    "      A sequence of convolutional layers that first apply the convolution operation over the\n",
    "      spatial dimensions, and then the temporal dimension. \n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([  \n",
    "        # Spatial decomposition\n",
    "        layers.Conv3D(filters=filters,\n",
    "                      kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
    "                      padding=padding),\n",
    "        # Temporal decomposition\n",
    "        layers.Conv3D(filters=filters, \n",
    "                      kernel_size=(kernel_size[0], 1, 1),\n",
    "                      padding=padding)\n",
    "        ],name=name)\n",
    "  \n",
    "  def call(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualMain(keras.layers.Layer):\n",
    "  \"\"\"\n",
    "    Residual block of the model with convolution, layer normalization, and the\n",
    "    activation function, ReLU.\n",
    "  \"\"\"\n",
    "  def __init__(self, filters, kernel_size,name):\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([\n",
    "        Conv3D(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same'),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.ReLU(),\n",
    "        Conv3D(filters=filters, \n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same'),\n",
    "        layers.LayerNormalization()\n",
    "    ], name=name)\n",
    "    \n",
    "  def call(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Frames_Per_Video = 10\n",
    "videoInput = layers.Input(shape = (Num_Frames_Per_Video, 224, 224, 3),name='videoInput')\n",
    "x = videoInput\n",
    "x = Conv3D(filters=32, kernel_size=(3, 7, 7), padding='same',name='videolayer1')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = ResidualMain(64, (3,3,3),name='videolayer2')(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = ResidualMain(32, (3,3,3),name='videolayer3')(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = ResidualMain(64, (3,3,3),name='videolayer4')(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024,name='vidoelyaer5')(x)\n",
    "videoFeatures = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a face subnetwork\n",
    "w_decay = 0.001\n",
    "\n",
    "# def FaceSubnet():\n",
    "faceInput = keras.layers.Input(shape=(224,224,3),name='faceInput')\n",
    "\n",
    "flayer1 = keras.layers.Conv2D(filters=96, kernel_size=(7,7), strides=(2,2), padding=\"same\", activation=\"relu\", name='flayer1i')\n",
    "\n",
    "fout1 = keras.layers.MaxPool2D(pool_size=(2,2),padding=\"valid\",name=\"flayer1o\")(flayer1(faceInput))\n",
    "\n",
    "flayer2 = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(2,2), padding=\"same\", activation=\"relu\",name='flayer2i')\n",
    "\n",
    "fout2 = keras.layers.MaxPool2D(pool_size=(2,2), padding=\"valid\",name='flayer2o')(flayer2(fout1))\n",
    "\n",
    "flayer3 = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1),padding=\"same\", activation=\"relu\",name='flayer3i')\n",
    "\n",
    "fout3 = keras.layers.MaxPool2D(pool_size=(2,2), padding=\"valid\",name='flayer3o')(flayer3(flayer3(flayer3(fout2))))\n",
    "\n",
    "flayer4 = keras.layers.Dense(units=4096, activation='relu',name='flayer4i')\n",
    "\n",
    "fout4 = keras.layers.Flatten(name='flayer40')(flayer4(fout3))\n",
    "\n",
    "flayer5 = keras.layers.Dense(units=1024, activation='relu',name='flayer5i')\n",
    "\n",
    "faceFeatures = flayer5(fout4)\n",
    "    \n",
    "\n",
    "# def VoiceSubnet():\n",
    "\n",
    "voiceInput = keras.layers.Input(shape=(20,130,1),name='voiceInput')\n",
    "\n",
    "vlayer1 = keras.layers.Conv2D(filters=96, kernel_size=(7,7), strides=(2,2), padding=\"same\", activation=\"relu\",name='vlayer1i')\n",
    "\n",
    "vout1 = keras.layers.MaxPool2D(pool_size=(2,2),padding=\"valid\",name='vlayer1o')(vlayer1(voiceInput))\n",
    "\n",
    "vlayer2 = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(2,2), padding=\"same\", activation=\"relu\",name='vlayer2i')\n",
    "\n",
    "vout2 = keras.layers.MaxPool2D(pool_size=(2,2), padding=\"valid\",name='vlayer2o')(vlayer2(vout1))\n",
    "\n",
    "vlayer3 = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1),padding=\"same\", activation=\"relu\",name='vlayer3i')\n",
    "\n",
    "vout3 = keras.layers.MaxPool2D(pool_size=(1,2), padding=\"valid\",name='vlayer3o')(vlayer3(vlayer3(vlayer3(vout2))))\n",
    "\n",
    "vlayer4 = keras.layers.Dense(units=4096, activation='relu',name='vlayer4i')\n",
    "\n",
    "vout4 = keras.layers.Flatten(name='valyer4o')(vlayer4(vout3))\n",
    "\n",
    "vlayer5 = keras.layers.Dense(units=1024, activation='relu',name='vlayer5i')\n",
    "\n",
    "voiceFeatures = vlayer5(vout4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedInputs = keras.layers.concatenate([faceFeatures,videoFeatures, voiceFeatures])\n",
    "\n",
    "clayer1 = keras.layers.Dense(1024, activation='relu',name='mlayer1')\n",
    "\n",
    "clayer2 = keras.layers.Dense(512, activation='relu',name='mlayer2')\n",
    "\n",
    "clayer3 = keras.layers.Dense(2, activation='relu',name='mlayer3')\n",
    "\n",
    "finalOutput = clayer3(clayer2(clayer1(combinedInputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(\n",
    "    inputs=[faceInput,videoInput, voiceInput],\n",
    "    outputs = finalOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 10, 224, 22  0           []                               \n",
      "                                4, 3)]                                                            \n",
      "                                                                                                  \n",
      " faceInput (InputLayer)         [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv3d_75 (Conv3D)             (None, 10, 224, 224  7840        ['input_6[0][0]']                \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " voiceInput (InputLayer)        [(None, 20, 130, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " flayer1i (Conv2D)              (None, 112, 112, 96  14208       ['faceInput[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 10, 224, 224  128        ['conv3d_75[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " vlayer1i (Conv2D)              (None, 10, 65, 96)   4800        ['voiceInput[0][0]']             \n",
      "                                                                                                  \n",
      " flayer1o (MaxPooling2D)        (None, 56, 56, 96)   0           ['flayer1i[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 10, 224, 224  0           ['batch_normalization_5[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " vlayer1o (MaxPooling2D)        (None, 5, 32, 96)    0           ['vlayer1i[0][0]']               \n",
      "                                                                                                  \n",
      " flayer2i (Conv2D)              (None, 28, 28, 256)  614656      ['flayer1o[0][0]']               \n",
      "                                                                                                  \n",
      " residual_main_11 (ResidualMain  (None, 10, 224, 224  80384      ['re_lu_22[0][0]']               \n",
      " )                              , 64)                                                             \n",
      "                                                                                                  \n",
      " vlayer2i (Conv2D)              (None, 3, 16, 256)   614656      ['vlayer1o[0][0]']               \n",
      "                                                                                                  \n",
      " flayer2o (MaxPooling2D)        (None, 14, 14, 256)  0           ['flayer2i[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 10, 224, 224  0           ['residual_main_11[0][0]']       \n",
      "                                , 64)                                                             \n",
      "                                                                                                  \n",
      " vlayer2o (MaxPooling2D)        (None, 1, 8, 256)    0           ['vlayer2i[0][0]']               \n",
      "                                                                                                  \n",
      " flayer3i (Conv2D)              (None, 14, 14, 256)  590080      ['flayer2o[0][0]',               \n",
      "                                                                  'flayer3i[0][0]',               \n",
      "                                                                  'flayer3i[1][0]']               \n",
      "                                                                                                  \n",
      " residual_main_12 (ResidualMain  (None, 10, 224, 224  34048      ['re_lu_24[0][0]']               \n",
      " )                              , 32)                                                             \n",
      "                                                                                                  \n",
      " vlayer3i (Conv2D)              (None, 1, 8, 256)    590080      ['vlayer2o[0][0]',               \n",
      "                                                                  'vlayer3i[0][0]',               \n",
      "                                                                  'vlayer3i[1][0]']               \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 10, 224, 224  0           ['residual_main_12[0][0]']       \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " residual_main_13 (ResidualMain  (None, 10, 224, 224  80384      ['re_lu_26[0][0]']               \n",
      " )                              , 64)                                                             \n",
      "                                                                                                  \n",
      " flayer3o (MaxPooling2D)        (None, 7, 7, 256)    0           ['flayer3i[2][0]']               \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 10, 224, 224  0           ['residual_main_13[0][0]']       \n",
      "                                , 64)                                                             \n",
      "                                                                                                  \n",
      " vlayer3o (MaxPooling2D)        (None, 1, 4, 256)    0           ['vlayer3i[2][0]']               \n",
      "                                                                                                  \n",
      " flayer4i (Dense)               (None, 7, 7, 4096)   1052672     ['flayer3o[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling3d_3 (Gl  (None, 64)          0           ['re_lu_28[0][0]']               \n",
      " obalAveragePooling3D)                                                                            \n",
      "                                                                                                  \n",
      " vlayer4i (Dense)               (None, 1, 4, 4096)   1052672     ['vlayer3o[0][0]']               \n",
      "                                                                                                  \n",
      " flayer40 (Flatten)             (None, 200704)       0           ['flayer4i[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 64)           0           ['global_average_pooling3d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " valyer4o (Flatten)             (None, 16384)        0           ['vlayer4i[0][0]']               \n",
      "                                                                                                  \n",
      " flayer5i (Dense)               (None, 1024)         205521920   ['flayer40[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         66560       ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " vlayer5i (Dense)               (None, 1024)         16778240    ['valyer4o[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3072)         0           ['flayer5i[0][0]',               \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'vlayer5i[0][0]']               \n",
      "                                                                                                  \n",
      " mlayer1 (Dense)                (None, 1024)         3146752     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " mlayer2 (Dense)                (None, 512)          524800      ['mlayer1[0][0]']                \n",
      "                                                                                                  \n",
      " mlayer3 (Dense)                (None, 2)            1026        ['mlayer2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,775,906\n",
      "Trainable params: 230,775,842\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainDataset,epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the learned model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('dynamicModel1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
